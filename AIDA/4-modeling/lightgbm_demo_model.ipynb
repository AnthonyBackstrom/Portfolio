{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d548e075-5900-48fb-9be7-2d85843f77bb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.model_selection import cross_val_score\n",
    "import lightgbm as lgb\n",
    "from lightgbm.callback import early_stopping\n",
    "\n",
    "# Load the dataset\n",
    "df = pd.read_csv('final_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "852423ae-af0c-4cc6-87e5-067d9b5fdaa7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.024836 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1417\n",
      "[LightGBM] [Info] Number of data points in the train set: 1409224, number of used features: 84\n",
      "[LightGBM] [Info] Start training from score 30691.202544\n",
      "Training until validation scores don't improve for 150 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[21461]\tvalid_0's l2: 8.91646e+06\n",
      "Root Mean Squared Error: 3001.835109409577\n",
      "R^2 Score: 0.9653814855057747\n"
     ]
    }
   ],
   "source": [
    "# Selecting the desired features for the model and the target variable\n",
    "X = df[['body_type', 'city_fuel_economy',  'fuel_tank_volume', 'fuel_type', 'highway_fuel_economy', 'horsepower', 'make_name', 'mileage', 'seller_rating', 'torque', 'transmission', 'year',  'major_options_count'\n",
    "]]  # Features\n",
    "y = df['price']  # Target variable\n",
    "\n",
    "# käytettävät sarakkeet:\n",
    "# make_name, fuel_type, body_type, transmission, mileage, year, horsepower, torque, major_options_count, fuel_tank_volume, highway_fuel_economy, city_fuel_economy, seller_rating\n",
    "\n",
    "# One-Hot Encoding categorial features\n",
    "categorical_features = ['body_type', 'fuel_type', 'make_name', 'transmission',]\n",
    "numerical_features = ['city_fuel_economy', 'highway_fuel_economy', 'fuel_tank_volume', 'horsepower', 'mileage', 'major_options_count', 'seller_rating', 'torque', 'year' ]\n",
    "\n",
    "# Creating preprocessing pipelines for categorical features\n",
    "categorical_pipeline = Pipeline(steps=[\n",
    "    ('onehot', OneHotEncoder(handle_unknown='ignore'))  # Applies One-Hot Encoding\n",
    "])\n",
    "\n",
    "# No transformation for numerical features in this pipeline\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('cat', categorical_pipeline, categorical_features),\n",
    "        ('num', 'passthrough', numerical_features)  # No changes to numerical features\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Splitting the data into training, validation, and testing sets\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.4, random_state=42)\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42)\n",
    "\n",
    "# Apply preprocessing to the training and validation data\n",
    "X_train_preprocessed = preprocessor.fit_transform(X_train)\n",
    "X_val_preprocessed = preprocessor.transform(X_val)\n",
    "X_test_preprocessed = preprocessor.transform(X_test)\n",
    "\n",
    "# Define the LightGBM model\n",
    "model = lgb.LGBMRegressor(\n",
    "    objective='regression', \n",
    "    n_estimators=21485,\n",
    "    learning_rate=0.037,\n",
    "    num_leaves=180, \n",
    "    max_depth=-1,\n",
    "    n_jobs=7, \n",
    "    random_state=42,\n",
    "    min_child_samples=6,\n",
    "    #subsample=0.8,\n",
    "    #colsample_bytree=0.8,\n",
    "    #force_row_wise=True\n",
    "    #force_col_wise=True\n",
    ")\n",
    "\n",
    "# Fit the model with early stopping using callback\n",
    "model.fit(\n",
    "    X_train_preprocessed, y_train, \n",
    "    eval_set=[(X_val_preprocessed, y_val)], \n",
    "    callbacks=[early_stopping(stopping_rounds=150, verbose=True)]\n",
    ")\n",
    "\n",
    "# Predicting the 'price' for the test data\n",
    "y_pred = model.predict(X_test_preprocessed)\n",
    "\n",
    "# Calculating the performance of the predictions\n",
    "rmse = np.sqrt(mean_squared_error(y_test,y_pred))\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "# Printing performance metrics\n",
    "print(f'Root Mean Squared Error: {rmse}')\n",
    "print(f'R^2 Score: {r2}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4948d003-d987-4b4d-a1e0-990073125a1e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Root Mean Squared Error: 3001.835109409577\n",
      "R^2 Score: 0.9653814855057747\n"
     ]
    }
   ],
   "source": [
    "# Predicting the 'price' for the test data\n",
    "# y_pred = model.predict(X_test_preprocessed)\n",
    "\n",
    "# Calculating the performance of the predictions\n",
    "rmse = np.sqrt(mean_squared_error(y_test,y_pred))\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "# Printing performance metrics\n",
    "print(f'Root Mean Squared Error: {rmse}')\n",
    "print(f'R^2 Score: {r2}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "647fae27-e62f-4b9b-888b-245e68f86b04",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        Actual Price  Predicted Price   Difference  Difference%\n",
      "145619       12999.0     11994.136388 -1004.863612     7.730315\n",
      "208243       67853.0     64105.911237 -3747.088763     5.522363\n",
      "345230       32778.0     32054.204903  -723.795097     2.208173\n",
      "348720       50685.0     51768.918438  1083.918438     2.138539\n",
      "422610       37880.0     37581.272344  -298.727656     0.788616\n",
      "168818       47495.0     44257.611070 -3237.388930     6.816273\n",
      "379784       31515.0     31028.770748  -486.229252     1.542850\n",
      "434764       44461.0     44201.839880  -259.160120     0.582893\n",
      "206407       31995.0     30210.013324 -1784.986676     5.578955\n",
      "414063        9990.0     10083.114023    93.114023     0.932072\n",
      "250162       14500.0     15131.788387   631.788387     4.357161\n",
      "314061       14675.0     14255.687729  -419.312271     2.857324\n",
      "396986       19995.0     19748.248237  -246.751763     1.234067\n",
      "249898       39999.0     41744.690592  1745.690592     4.364336\n",
      "15470        23182.0     28099.979653  4917.979653    21.214648\n"
     ]
    }
   ],
   "source": [
    "# Comparing predicted prices with actual prices\n",
    "comparison_df = pd.DataFrame({'Actual Price': y_test, 'Predicted Price': y_pred})\n",
    "comparison_df['Difference'] = comparison_df['Predicted Price'] - comparison_df['Actual Price']\n",
    "comparison_df['Difference%'] = np.abs(comparison_df['Difference'] / comparison_df['Actual Price'] * 100)\n",
    "\n",
    "# Sorting the DataFrame by the difference percentage to see the predictions with the biggest discrepancies\n",
    "comparison_df.sort_values(by='Difference%', ascending=False, inplace=True)\n",
    "\n",
    "# Reset index for better readability\n",
    "comparison_df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# Generate a random sample from the comparison dataframe\n",
    "random_comparison_sample = comparison_df.sample(n=15, random_state=None)  # 'n' is the number of samples\n",
    "\n",
    "# Display the random sample\n",
    "print(random_comparison_sample)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
