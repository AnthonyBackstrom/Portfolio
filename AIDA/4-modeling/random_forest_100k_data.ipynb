{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "51c2bc62-d250-49d8-b369-04c8fb07c262",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "# Load the dataset\n",
    "df = pd.read_csv('model_data_100k.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a50dcfa0-47cd-4d61-be14-9a4c8b515aa4",
   "metadata": {},
   "source": [
    "### Malli\n",
    "Random Forest\n",
    "\n",
    "Kokeiltu myös Linear Regressionia jolla sain huonoja tuloksia\n",
    "\n",
    "Voi testata vaihtelemalla hyperparametreja, datatiedostoa ja käytettäviä sarakkeita. \n",
    "\n",
    "Testissä käytetty datatiedostoa joka sisältää 100 000 ensimmäistä riviä alkuperäisestä datasta koodin suoritusajan nopeuttamiseksi. \n",
    "\n",
    "Dataa on myös muokattu, kuten tyhjät arvot korvattu False:lla joissain tapauksissa, sekä käytetty mediaania tai keskiarvoa tyhjien arvojen kohdalla tietyissä sarakkeissa jne.\n",
    "\n",
    "##### HUOM, mallin tarkkuus on hyvä, mutta kun virheitä arvioinnissa tulee, niin hinnan heitto voi olla todella suurta."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7f7c40d5-4df0-4e59-9fff-dd388d8d3680",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error: 27809348.09484101\n",
      "Root Mean Squared Error: 5273.456939697243\n",
      "R^2 Score: 0.9271776014121227\n",
      "       Actual Price  Predicted Price   Difference  Difference%\n",
      "9328        29740.0     31651.819385  1911.819385     6.428444\n",
      "372          9995.0     14356.160000  4361.160000    43.633417\n",
      "14160       23737.0     24382.094843   645.094843     2.717676\n",
      "18288       40988.0     41240.150000   252.150000     0.615180\n",
      "12440       47368.0     49188.519683  1820.519683     3.843353\n",
      "15324       38368.0     39159.261503   791.261503     2.062295\n",
      "4406        42795.0     37226.990000 -5568.010000    13.010889\n",
      "14702       29770.0     29052.993964  -717.006036     2.408485\n",
      "16969       26545.0     26225.610308  -319.389692     1.203201\n",
      "1651         2995.0      2325.340000  -669.660000    22.359265\n",
      "3047        20395.0     17058.070000 -3336.930000    16.361510\n",
      "13784       40998.0     42210.960000  1212.960000     2.958583\n",
      "6809         5900.0      5354.340000  -545.660000     9.248475\n",
      "19931       29195.0     29191.000000    -4.000000     0.013701\n",
      "3832        28699.0     24619.970000 -4079.030000    14.213143\n"
     ]
    }
   ],
   "source": [
    "# Selecting the desired features for the model and the target variable\n",
    "X = df[['mileage', 'horsepower', 'year', 'seller_rating', 'city_fuel_economy', 'make_name', 'body_type', 'wheel_system', 'isCab', 'transmission', 'fuel_type', \"is_cpo\", \"is_oemcpo\"]]  # Features\n",
    "y = df['price']  # Target variable\n",
    "\n",
    "# All the columns that can be used in training:\n",
    "# \"city_fuel_economy\", \"body_type\",\n",
    "# \"horsepower\", \"exterior_color\", \"mileage\",\n",
    "# \"make_name\", \"model_name\", \"year\", \"wheel_system\", \"seller_rating\", \"is_new\", \n",
    "# \"is_cpo\", \"is_oemcpo\", \"isCab\", \"transmission\", \"fuel_type\", \"price\"\n",
    "\n",
    "\n",
    "# One-Hot Encoding categorial features\n",
    "categorical_features = ['make_name', 'body_type', 'wheel_system', 'isCab', 'transmission', 'fuel_type', \"is_cpo\", \"is_oemcpo\"]\n",
    "numerical_features = ['mileage', 'horsepower', 'year', 'seller_rating', 'city_fuel_economy']\n",
    "\n",
    "# Creating preprocessing pipelines for categorical features\n",
    "categorical_pipeline = Pipeline(steps=[\n",
    "    ('onehot', OneHotEncoder(handle_unknown='ignore'))  # Applies One-Hot Encoding\n",
    "])\n",
    "\n",
    "# No transformation for numerical features in this pipeline\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('cat', categorical_pipeline, categorical_features),\n",
    "        ('num', 'passthrough', numerical_features)  # No changes to numerical features\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Splitting the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Creating a Random Forest model\n",
    "model = RandomForestRegressor(n_estimators=100, random_state=42, n_jobs=6)\n",
    "# Consider setting max_depth if necessary!\n",
    "\n",
    "# Creating the final pipeline including preprocessing and the model\n",
    "pipeline = Pipeline([\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('model', model)\n",
    "])\n",
    "\n",
    "# Training the model with the training data\n",
    "pipeline.fit(X_train, y_train)\n",
    "\n",
    "# Predicting the 'price' for the test data\n",
    "y_pred = pipeline.predict(X_test)\n",
    "\n",
    "# Calculating the performance of the predictions\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "rmse = np.sqrt(mean_squared_error(y_test,y_pred))\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "# Printing performance metrics\n",
    "print(f'Mean Squared Error: {mse}')\n",
    "print(f'Root Mean Squared Error: {rmse}')\n",
    "print(f'R^2 Score: {r2}')\n",
    "\n",
    "\n",
    "# Comparing predicted prices with actual prices\n",
    "comparison_df = pd.DataFrame({'Actual Price': y_test, 'Predicted Price': y_pred})\n",
    "comparison_df['Difference'] = comparison_df['Predicted Price'] - comparison_df['Actual Price']\n",
    "comparison_df['Difference%'] = np.abs(comparison_df['Difference'] / comparison_df['Actual Price'] * 100)\n",
    "\n",
    "# Sorting the DataFrame by the difference percentage to see the predictions with the biggest discrepancies\n",
    "comparison_df.sort_values(by='Difference%', ascending=False, inplace=True)\n",
    "\n",
    "# Reset index for better readability\n",
    "comparison_df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# Generate a random sample from the comparison dataframe\n",
    "random_comparison_sample = comparison_df.sample(n=15, random_state=None)  # 'n' is the number of samples\n",
    "\n",
    "# Display the random sample\n",
    "print(random_comparison_sample)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
